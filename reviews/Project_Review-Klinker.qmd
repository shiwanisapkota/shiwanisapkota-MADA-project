---
title: Project Review Template 
author: YOUR NAME
date: "`r file.mtime(knitr::current_input())`"
format: 
  html:
    toc: true
    toc-depth: 3
    number-sections: true
---

# Overview

Title of project: Trend in mammogram screening for breast cancer and socio-economic status of Hispanic and non-Hispanic women during 2000, 2005, 2010, and 2015

Name of project author(s): Shiwani Sapkota

Name of project reviewer: Abbie Klinker

# Specific project content evaluation
Evaluate the different parts of the project by filling in the sections below.

## Background, Context and Motivation
How well is the context of the project described? Is a comprehensive background, including summary of previous/related work given? Is the project well placed into the context of existing work (including proper referencing of existing work). Is it clear why the project was undertaken and what new information it hopes to provide?

### Feedback and Comments

Great background information, well sourced, and detailed descriptions included about the context of the project itself and the data.

### Summary assessment (PICK ONE, DELETE THE OTHERS)

* strong contextualization and motivation


## Question description
How well and clear are the question(s)/hypotheses the project aims to address described? Is it clear how the questions relate to the data?


### Feedback and Comments

I'm scoring this section a bit lower, not because the author's description was not clear, but because there's no official "question" or hypothesis outlined in the manuscript. Rather, the author describes the project as exploratory in nature to investigate the relationship trend among socio-demographic factors influencing the likelihood of using mammography screening services.

I don't think this is inadequate, but given how this evaluation section was phrased, I'm not sure if Dr. Handel is looking for something a bit more concrete of a research question/specific hypothesis of the outcomes.

### Summary assessment

* question/hypotheses somewhat explained

## Data description
How well is the data overall described? Is the source provided? Is a codebook or other meta-information available that makes it clear what the data is? 

### Feedback and Comments

Noted a bit earlier, but data well described in its source and inclusion criteria. 

### Summary assessment

* source and overall structure of data well explained

## Data wrangling and exploratory analysis
How well is the data cleaned/processed and explored? Are all steps reasonable and well explained? Are alternatives discussed and considered? Are meaningful exploratory results shown (e.g. in the supplementary materials)?

### Feedback and Comments

WRITE YOUR FEEDBACK HERE

### Summary assessment
* major weaknesses in wrangling and exploratory component
* some weaknesses in wrangling and exploratory component
* essentially no weaknesses in wrangling and exploratory component



## Appropriateness of Analysis
Were the analysis methods appropriate for the data? Was the analysis done properly? Were different components of the analysis (e.g. performance measure, variable selection, data pre-processing, model evaluation) done in the best way possible and explained well?

### Feedback and Comments

This isn't related to the actual analysis methods used, but I'm so impressed by how you were able to view the decision tree output. I have had so much trouble in accessing metrics and performance of ML models using tidymodels and it looks so cool!

### Summary assessment

* strong and reasonable analysis

## Presentation
How well are results presented? Are tables and figures easy to read and understand? Are the main figures/tables publication level quality? 

### Feedback and Comments

Table 1 and Graph 1 have a mix of variable names and descriptive names. For Table 2, I'm not sure how necessary it is to list out all factors used versus total model evaluation, especially since no measure of total model evaluation was used, until in comparison with the other single-factor models. Other than that, everything looks great! 

### Summary assessment

* results are very well presented


## Discussion/Conclusions
Are the study findings properly discussed? Are strengths and limitations acknowledged? Are findings interpreted properly?

### Feedback and Comments

Nicely done! 

### Summary assessment

* strong, complete and clear discussion


## Further comments

_Add any other comments regarding the different aspects of the project here. Write anything you think can help your classmate improve their project._



# Overall project content evaluation
Evaluate overall features of the project  by filling in the sections below.


## Structure
Is the project well structured? Are files in well labeled folders? Do files have reasonable names? Are all "junk" files not needed for analysis/reproduction removed? By just looking at files and folders, can you get an idea of how things fit together?

### Feedback and Comments

The project was really well organized, and I had no trouble finding the files I needed or figuring out the order to run the code! 

### Summary assessment

* well structured


## Documentation 
How well is the project documented? Are you able to understand each step of the whole analysis, each decision that was made, and each line of code? Is enough information provided as comments in code or as part of Rmd files? 

### Feedback and Comments

There was a lot of documentation throughout the project, either small notes in the code as comments or next steps outlined through text in the Rmd files. 

### Summary assessment

* fully and well documented


## Reproducibility
Are all results fully reproducible? Is documentation provided which clearly explains how to reproduce things, and does it work without the need for any manual intervention? Are you able to re-run the whole analysis without having to do manual interventions/edits?

### Feedback and Comments

All code ran with no problem; however, I could not get the actual manuscript to knit, and it seems like a problem with one of the markdown specifications. I'm not 100% sure how to fix it - if I need an extra package on my end or if something's a bit off with the specifications.


### Summary assessment

* fully reproducible without issues


## Thoroughness
How thorough was the overall study? Were alternatives (e.g. different ways of processing the data or different models) considered? Were alternatives discussed? Were the questions/hypotheses fully and thoroughly addressed?

### Feedback and Comments

Several non-ML and several ML models concered and analyzed.

### Summary assessment

* strong level of thoroughness


## Further comments

Good work! My main feedback is to double check knitting your manuscript with a clear environment and maybe cleaning up variable names in tables, but great project! 




